# TRINITY Vision Aid - Quick Start Guide

Schnelleinstieg f√ºr Entwickler, die sofort mit TRINITY arbeiten m√∂chten.

## 5-Minuten-Setup

### 1. Voraussetzungen pr√ºfen

```bash
# Xcode installiert?
xcode-select -p
# Sollte ausgeben: /Applications/Xcode.app/Contents/Developer

# iOS Deployment Target
# Mindestens: iOS 17.0

# Ger√§t
# iPhone 17 Pro oder neuer (mit LiDAR)
```

### 2. Projekt klonen & √∂ffnen

```bash
git clone https://github.com/yourusername/TRINITY.git
cd TRINITY
open -a Xcode .
```

### 3. Xcode Projekt erstellen (erstmaliges Setup)

Falls noch kein `.xcodeproj` existiert:

1. Xcode √∂ffnen
2. **File ‚Üí New ‚Üí Project ‚Üí iOS App**
3. Settings:
   - Name: `TRINITY`
   - Bundle ID: `com.trinity.visionaid`
   - Interface: **SwiftUI**
   - Language: **Swift**
4. Speichern im `TRINITY` Ordner

### 4. Source Files hinzuf√ºgen

```bash
# In Xcode Navigator:
# Rechtsklick auf TRINITY ‚Üí Add Files to "TRINITY"
# W√§hle: TrinityApp/Sources/ (alle Ordner)
# ‚úÖ Copy items if needed
# ‚úÖ Create groups
```

### 5. Frameworks verkn√ºpfen

**Target ‚Üí Build Phases ‚Üí Link Binary With Libraries ‚Üí +**

Hinzuf√ºgen:
- ARKit
- AVFoundation
- CoreML
- Vision
- CoreLocation
- CloudKit
- NaturalLanguage

### 6. Info.plist kopieren

```bash
cp TrinityApp/Info.plist TRINITY/TRINITY/Info.plist
```

Oder manuell Permissions hinzuf√ºgen:
- Camera Usage
- Location Usage
- ARKit Usage

### 7. Build & Run

```bash
# In Xcode:
Cmd + R

# Oder via Command Line:
xcodebuild -scheme TRINITY -destination 'platform=iOS,name=Your iPhone'
```

## Erste Schritte im Code

### Verstehen der Architektur

```swift
// 1. Entry Point: TrinityApp.swift
@main
struct TrinityApp: App {
    @StateObject private var coordinator: TrinityCoordinator
    // ...
}

// 2. Coordinator: TrinityCoordinator.swift
class TrinityCoordinator {
    // Orchestriert alle Komponenten
    private let sensorManager: SensorManager
    private let memoryManager: MemoryManager
    private let agents: [Agent]
    // ...
}

// 3. Sensors: SensorManager.swift
class SensorManager {
    // Verwaltet Kamera, LiDAR, Location
    private var arSession: ARSession
    // ...
}

// 4. Memory: MemoryManager.swift
class MemoryManager {
    // 3-Schicht Ged√§chtnis
    var workingMemory: [VectorEntry]
    var episodicMemory: [VectorEntry]
    var semanticMemory: [VectorEntry]
    // ...
}

// 5. Agents: Agent.swift + Implementierungen
protocol Agent {
    func process(_ input: Input) async throws -> Output
}
```

### Datenfluss verstehen

```
1. Sensor Input
   ‚Üì
2. SensorManager (ARFrame, Location)
   ‚Üì
3. PerceptionAgent (Objekterkennung)
   ‚Üì
4. EmbeddingGenerator (Vector)
   ‚Üì
5. MemoryManager (Speichern + Suchen)
   ‚Üì
6. ContextAgent (Kontext aufbauen)
   ‚Üì
7. NavigationAgent (Hindernisse)
   ‚Üì
8. CommunicationAgent (Sprache)
   ‚Üì
9. Audio Output + Haptics
```

## Typische Entwicklungsaufgaben

### Task 1: Neues Objekt erkennen

**Datei**: `Agents/PerceptionAgent.swift`

```swift
// Zeile ~50: processVisionFrame
private func processVisionFrame(_ imageData: Data) async throws -> [DetectedObject] {
    // Hier Vision Framework Integration

    let request = VNRecognizeObjectsRequest { request, error in
        // Verarbeite Ergebnisse
    }

    // F√ºhre Request aus
}
```

### Task 2: Neue Memory-Query

**Datei**: `Memory/MemoryManager.swift`

```swift
// Zeile ~100: search
func search(embedding: [Float], topK: Int = 5) async throws -> [VectorEntry] {
    // Suche √ºber alle Memory Layers
    var results: [VectorEntry] = []

    // Working Memory durchsuchen
    results += workingMemory.filter { ... }

    return results.sorted { $0.similarity > $1.similarity }
}
```

### Task 3: UI anpassen

**Datei**: `UI/MainView.swift`

```swift
// Zeile ~30: VStack mit Buttons
VStack(spacing: 30) {
    // Neuen Button hinzuf√ºgen
    ActionButton(
        title: "Neue Funktion",
        icon: "star.fill",
        action: {
            // Action hier
        }
    )
}
```

### Task 4: Neuen Agent hinzuf√ºgen

**Neue Datei**: `Agents/MyAgent.swift`

```swift
class MyAgent: BaseAgent<MyInput, MyOutput> {
    override init() {
        super.init(name: "MyAgent")
    }

    override func process(_ input: MyInput) async throws -> MyOutput {
        // Implementierung
        return MyOutput(...)
    }
}

// In TrinityCoordinator registrieren:
agentCoordinator.register(myAgent)
```

## Debugging

### Sensor-Daten testen

```swift
// In TrinityCoordinator.swift, Zeile ~150
private func processObservation(_ observation: Observation) async {
    // Debug-Output hinzuf√ºgen:
    print("üì∏ Observation:")
    print("  - Timestamp: \(observation.timestamp)")
    print("  - Objects: \(observation.detectedObjects.count)")
    print("  - Location: \(observation.location?.coordinate)")
}
```

### Memory-Inhalte anzeigen

```swift
// In MemoryManager.swift
func debugPrint() {
    print("üß† Memory Status:")
    print("  - Working: \(workingMemory.count)")
    print("  - Episodic: \(episodicMemory.count)")
    print("  - Semantic: \(semanticMemory.count)")
}
```

### Embedding-Qualit√§t pr√ºfen

```swift
// In EmbeddingGenerator.swift
func debugEmbedding(_ embedding: [Float]) {
    let magnitude = sqrt(embedding.map { $0 * $0 }.reduce(0, +))
    print("üî¢ Embedding:")
    print("  - Dimension: \(embedding.count)")
    print("  - Magnitude: \(magnitude)")
    print("  - First 5: \(embedding.prefix(5))")
}
```

## Testing

### Unit Test Beispiel

**Datei**: `Tests/MemoryManagerTests.swift`

```swift
import XCTest
@testable import TRINITY

class MemoryManagerTests: XCTestCase {
    var memoryManager: MemoryManager!

    override func setUp() async throws {
        let vectorDB = try VectorDatabase()
        memoryManager = MemoryManager(vectorDatabase: vectorDB)
    }

    func testAddObservation() async throws {
        let observation = createTestObservation()
        let embedding = [Float](repeating: 0.5, count: 512)

        try await memoryManager.addObservation(observation, embedding: embedding)

        XCTAssertEqual(memoryManager.workingMemory.count, 1)
    }
}
```

### UI Test Beispiel

**Datei**: `Tests/MainViewTests.swift`

```swift
import XCTest

class MainViewUITests: XCTestCase {
    func testStartButton() throws {
        let app = XCUIApplication()
        app.launch()

        let startButton = app.buttons["Start TRINITY"]
        XCTAssertTrue(startButton.exists)

        startButton.tap()

        // √úberpr√ºfe Status-√Ñnderung
        XCTAssertTrue(app.staticTexts["Running"].exists)
    }
}
```

## Performance-Profiling

### Instruments verwenden

```bash
# In Xcode:
Cmd + I

# Instrumente w√§hlen:
# - Time Profiler (CPU)
# - Allocations (Memory)
# - Energy Log (Battery)
```

### Kritische Performance-Bereiche

1. **Embedding-Generierung**: Sollte < 100ms sein
2. **Vector Search**: Sollte < 20ms sein (10k Vektoren)
3. **UI Updates**: Sollte < 16ms sein (60 FPS)

## H√§ufige Probleme & L√∂sungen

### Problem: "ARKit not available"

```swift
// L√∂sung: Simulator unterst√ºtzt kein ARKit
// Testen Sie auf physischem Ger√§t
guard ARWorldTrackingConfiguration.isSupported else {
    print("‚ö†Ô∏è ARKit nicht verf√ºgbar")
    return
}
```

### Problem: "Memory not persisting"

```swift
// L√∂sung: Speichern vergessen
await memoryManager.saveMemories()

// Oder Auto-Save aktivieren:
NotificationCenter.default.addObserver(
    forName: UIApplication.didEnterBackgroundNotification,
    object: nil,
    queue: nil
) { _ in
    Task {
        try? await memoryManager.saveMemories()
    }
}
```

### Problem: "Voice output not working"

```swift
// L√∂sung: Berechtigungen pr√ºfen
AVAudioSession.sharedInstance().requestRecordPermission { granted in
    if !granted {
        print("‚ö†Ô∏è Audio Berechtigung fehlt")
    }
}
```

## N√§chste Schritte

Nach dem Quick Start:

1. ‚úÖ **ARCHITECTURE.md** lesen
2. ‚úÖ Code-Kommentare durchgehen
3. ‚úÖ Erste Tests auf iPhone ausf√ºhren
4. ‚úÖ Mit VoiceOver testen
5. ‚úÖ Eigene Features entwickeln

## Ressourcen

- **Apple Docs**: [ARKit](https://developer.apple.com/arkit)
- **Core ML**: [Machine Learning](https://developer.apple.com/machine-learning)
- **SwiftUI**: [Tutorial](https://developer.apple.com/tutorials/swiftui)
- **Accessibility**: [Guidelines](https://developer.apple.com/accessibility)

## Community

- **GitHub**: Issues & Discussions
- **Stack Overflow**: Tag `trinity-vision-aid`
- **Discord**: [Link folgt]

---

**Happy Coding!** üöÄ

Fragen? ‚Üí √ñffnen Sie ein GitHub Issue
