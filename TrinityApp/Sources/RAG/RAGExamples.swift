//
//  RAGExamples.swift
//  TRINITY Vision Aid
//
//  Example usage patterns for RAG system
//

import Foundation

/// Example implementations for X/Twitter
class RAGExamples {
    
    // MARK: - Basic RAG Pattern
    
    /// ğŸ§  Simple RAG Query
    static func basicRAGExample() async throws {
        // Setup
        let vectorDB = try VectorDatabase()
        let embeddings = try EmbeddingGenerator()
        let ragEngine = RAGQueryEngine(
            vectorDatabase: vectorDB,
            embeddingGenerator: embeddings
        )
        
        // Query
        let response = try await ragEngine.query("What objects did I see today?")
        
        print("Answer: \(response.answer)")
        print("Confidence: \(response.confidence)")
        print("Sources: \(response.sources.count) documents")
    }
    
    // MARK: - Vision-Based RAG
    
    /// ğŸ“¸ RAG with Vision Input
    static func visionRAGExample(observation: Observation) async throws {
        let vectorDB = try VectorDatabase()
        let embeddings = try EmbeddingGenerator()
        let ragEngine = RAGQueryEngine(
            vectorDatabase: vectorDB,
            embeddingGenerator: embeddings
        )
        
        // Query based on what you're seeing
        let response = try await ragEngine.query(
            observation: observation,
            question: "What is this object and when did I last see it?"
        )
        
        print(response.answer)
    }
    
    // MARK: - Conversational RAG
    
    /// ğŸ’¬ Multi-turn Conversation
    static func conversationalRAGExample() async throws {
        let vectorDB = try VectorDatabase()
        let embeddings = try EmbeddingGenerator()
        let ragEngine = RAGQueryEngine(
            vectorDatabase: vectorDB,
            embeddingGenerator: embeddings
        )
        
        var history: [RAGResponse] = []
        
        // Turn 1
        let response1 = try await ragEngine.query("What's in front of me?")
        history.append(response1)
        
        // Turn 2 (with context)
        let response2 = try await ragEngine.conversationalQuery(
            question: "How far away is it?",
            history: history
        )
        history.append(response2)
        
        print("Conversation:")
        for (i, response) in history.enumerated() {
            print("Q\(i+1): \(response.query)")
            print("A\(i+1): \(response.answer)\n")
        }
    }
    
    // MARK: - Hybrid Search RAG
    
    /// ğŸ” Hybrid Search (Semantic + Keyword)
    static func hybridSearchExample() async throws {
        let vectorDB = try VectorDatabase()
        let embeddings = try EmbeddingGenerator()
        let retriever = RAGRetriever(
            vectorDatabase: vectorDB,
            embeddingGenerator: embeddings
        )
        
        // Combine semantic search with keywords
        let documents = try await retriever.hybridSearch(
            query: "dangerous obstacles",
            keywords: ["obstacle", "warning", "danger"],
            config: .default
        )
        
        for doc in documents {
            print("Found: \(doc.content) (similarity: \(doc.similarity))")
        }
    }
    
    // MARK: - Custom Retrieval Config
    
    /// âš™ï¸ Advanced Retrieval Configuration
    static func advancedRetrievalExample() async throws {
        let vectorDB = try VectorDatabase()
        let embeddings = try EmbeddingGenerator()
        let ragEngine = RAGQueryEngine(
            vectorDatabase: vectorDB,
            embeddingGenerator: embeddings
        )
        
        // Custom config
        let config = RetrievalConfig(
            topK: 10,
            similarityThreshold: 0.8,
            layers: [.episodic, .semantic], // Skip working memory
            reranking: true
        )
        
        let response = try await ragEngine.query(
            "Where have I been this week?",
            config: config
        )
        
        print(response.answer)
    }
    
    // MARK: - Batch Processing
    
    /// ğŸ“¦ Batch Query Processing
    static func batchQueryExample() async throws {
        let vectorDB = try VectorDatabase()
        let embeddings = try EmbeddingGenerator()
        let ragEngine = RAGQueryEngine(
            vectorDatabase: vectorDB,
            embeddingGenerator: embeddings
        )
        
        let questions = [
            "What did I see today?",
            "Where did I go?",
            "What obstacles did I encounter?"
        ]
        
        let responses = try await ragEngine.batchQuery(questions: questions)
        
        for (question, response) in zip(questions, responses) {
            print("Q: \(question)")
            print("A: \(response.answer)\n")
        }
    }
    
    // MARK: - Diverse Results
    
    /// ğŸ¨ Retrieve with Diversity
    static func diverseRetrievalExample() async throws {
        let vectorDB = try VectorDatabase()
        let embeddings = try EmbeddingGenerator()
        let retriever = RAGRetriever(
            vectorDatabase: vectorDB,
            embeddingGenerator: embeddings
        )
        
        // Get diverse results (avoid too similar documents)
        let documents = try await retriever.retrieveWithDiversity(
            query: "objects in my environment",
            diversityThreshold: 0.85
        )
        
        for doc in documents {
            print("- \(doc.metadata.objectType): \(doc.metadata.description)")
        }
    }
    
    // MARK: - Real-World Use Cases
    
    /// ğŸƒ Navigation Assistant
    static func navigationAssistantExample() async throws {
        let vectorDB = try VectorDatabase()
        let embeddings = try EmbeddingGenerator()
        let ragEngine = RAGQueryEngine(
            vectorDatabase: vectorDB,
            embeddingGenerator: embeddings
        )
        
        // Check for obstacles
        let response = try await ragEngine.query(
            "Are there any obstacles within 2 meters?",
            config: RetrievalConfig(
                topK: 5,
                similarityThreshold: 0.6,
                layers: [.working],
                reranking: true
            )
        )
        
        if response.confidence > 0.7 {
            print("âš ï¸ Navigation Alert: \(response.answer)")
        }
    }
    
    /// ğŸ  Location Memory
    static func locationMemoryExample() async throws {
        let vectorDB = try VectorDatabase()
        let embeddings = try EmbeddingGenerator()
        let ragEngine = RAGQueryEngine(
            vectorDatabase: vectorDB,
            embeddingGenerator: embeddings
        )
        
        // Remember a location
        let response = try await ragEngine.query(
            "Have I been to this location before?",
            config: RetrievalConfig(
                topK: 3,
                similarityThreshold: 0.75,
                layers: [.episodic, .semantic],
                reranking: true
            )
        )
        
        print(response.answer)
        print("\nBased on \(response.sources.count) previous visits")
    }
    
    /// ğŸ“š Knowledge Retrieval
    static func knowledgeRetrievalExample() async throws {
        let vectorDB = try VectorDatabase()
        let embeddings = try EmbeddingGenerator()
        let ragEngine = RAGQueryEngine(
            vectorDatabase: vectorDB,
            embeddingGenerator: embeddings
        )
        
        // Query semantic memory for learned patterns
        let response = try await ragEngine.query(
            "What do I usually find in the kitchen?",
            config: RetrievalConfig(
                topK: 10,
                similarityThreshold: 0.5,
                layers: [.semantic],
                reranking: true
            )
        )
        
        print("Learned patterns: \(response.answer)")
    }
}

// MARK: - X/Twitter Code Snippets

extension RAGExamples {
    
    /// Tweet 1: Basic RAG in Swift ğŸ§µ
    static let tweet1 = """
    ğŸ§  Building a RAG system in Swift for vision assistance!
    
    RAG = Retrieval + Generation
    1ï¸âƒ£ Embed query â†’ vector
    2ï¸âƒ£ Search vector DB (HNSW)
    3ï¸âƒ£ Retrieve top-K documents
    4ï¸âƒ£ Generate answer with context
    
    Perfect for on-device ML! ğŸ
    #Swift #RAG #AI
    """
    
    /// Tweet 2: Code Example
    static let tweet2 = """
    ğŸ“¸ RAG with Vision Input in Swift:
    
    ```swift
    let ragEngine = RAGQueryEngine(
        vectorDB: vectorDB,
        embeddings: embeddings
    )
    
    let response = try await ragEngine.query(
        observation: currentFrame,
        question: "What's in front of me?"
    )
    ```
    
    Combines camera + LiDAR + memory! ğŸš€
    """
    
    /// Tweet 3: Architecture
    static let tweet3 = """
    ğŸ—ï¸ RAG Architecture for iOS:
    
    Observation â†’ Embedding â†’ VectorDB
         â†“           â†“           â†“
    MultiModal    CoreML     HNSW Index
         â†“           â†“           â†“
    Retriever â†’ Context â†’ Generator
    
    100% on-device, no cloud! ğŸ”’
    #PrivacyFirst
    """
    
    /// Tweet 4: Performance
    static let tweet4 = """
    âš¡ï¸ RAG Performance Metrics:
    
    Embedding: <100ms
    Vector Search (10k): <20ms
    Retrieval: <50ms
    Total: <300ms
    
    Memory: ~50MB
    Accuracy: 95%+
    
    Fast enough for real-time! â±ï¸
    """
}
