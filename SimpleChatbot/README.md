# ğŸ¤– Simple Chatbot - Lokale KI Ãœbungsprojekt

Ein einfacher Chatbot mit SwiftUI und lokaler KI-Integration - perfekt zum Ãœben von Xcode und Cursor!

## ğŸ“‹ Was ist das?

Dies ist ein Ãœbungsprojekt, um zu lernen:
- âœ… Wie man ein Xcode-Projekt strukturiert
- âœ… SwiftUI fÃ¼r moderne iOS/macOS Apps
- âœ… Ordner-Organisation (Xcode + Cursor kompatibel)
- âœ… Lokale KI-Integration (Vorbereitet fÃ¼r MLX, CoreML, llama.cpp)

## ğŸš€ Schnellstart

### Option 1: In Xcode Ã¶ffnen (Empfohlen)

1. **Xcode Ã¶ffnen**
   ```bash
   open SimpleChatbot/Package.swift
   ```
   Oder:
   - Doppelklick auf `Package.swift` im Finder

2. **Warten bis Dependencies geladen sind**
   - Xcode lÃ¤dt automatisch alle Pakete

3. **App auswÃ¤hlen**
   - Oben links: WÃ¤hlen Sie `SimpleChatbot` Schema
   - WÃ¤hlen Sie ein Target (z.B. "iPhone 15 Pro" oder "My Mac")

4. **Build & Run**
   - DrÃ¼cken Sie âŒ˜R oder klicken Sie auf â–¶ï¸ Play-Button

### Option 2: Mit Cursor bearbeiten

```bash
# Cursor im Projekt-Ordner Ã¶ffnen
cd /home/user/TRINITY
cursor SimpleChatbot/

# Oder von Ã¼berall:
cursor /home/user/TRINITY/SimpleChatbot
```

**In Cursor kÃ¶nnen Sie:**
- Code bearbeiten und AI-Assistenz nutzen
- Struktur verstehen und erweitern
- Neue Features hinzufÃ¼gen

**Dann in Xcode:**
- Build und Run ausfÃ¼hren
- App testen und debuggen

## ğŸ“ Projektstruktur

```
SimpleChatbot/
â”œâ”€â”€ Package.swift                    # Swift Package Definition
â”œâ”€â”€ README.md                        # Diese Datei
â””â”€â”€ SimpleChatbot/
    â”œâ”€â”€ App/
    â”‚   â””â”€â”€ SimpleChatbotApp.swift  # App Entry Point (@main)
    â”œâ”€â”€ Views/
    â”‚   â””â”€â”€ ChatView.swift          # Chat UI (SwiftUI)
    â”œâ”€â”€ Models/
    â”‚   â””â”€â”€ Message.swift           # Message Datenmodell
    â””â”€â”€ Services/
        â””â”€â”€ LocalAIService.swift    # KI-Service (aktuell simuliert)
```

**ğŸ’¡ Diese Struktur ist optimal fÃ¼r:**
- âœ… Xcode (klare Navigation)
- âœ… Cursor (sieht alle Ordner)
- âœ… Git (saubere Historie)

## ğŸ¯ Features

### Aktuell implementiert:
- âœ… Modernes SwiftUI Chat-Interface
- âœ… Nachrichten-Historie
- âœ… Auto-Scroll zu neuen Nachrichten
- âœ… Zeitstempel fÃ¼r jede Nachricht
- âœ… User/Bot Unterscheidung
- âœ… Simulierter KI-Service (regelbasiert)

### Chat-Funktionen zum Ausprobieren:
Probieren Sie in der App:
- "Hallo" â†’ BegrÃ¼ÃŸung
- "Wie heiÃŸt du?" â†’ Stellt sich vor
- "Wie funktionierst du?" â†’ ErklÃ¤rt lokale KI
- "Hilfe" â†’ Zeigt MÃ¶glichkeiten

## ğŸ”§ Erweitern mit echter lokaler KI

### Option 1: MLX Swift (Apple Silicon)

```swift
// In LocalAIService.swift ersetzen:

import MLX
import MLXRandom
import MLXNN

class LocalAIService: ObservableObject {
    private var model: LanguageModel?

    func loadModel() async {
        // Lade MLX Modell
        model = try? await LanguageModel.load("mlx-community/Llama-3.2-1B-4bit")
    }

    func generateResponse(for message: String) async -> String {
        guard let model = model else { return "Modell wird geladen..." }

        let prompt = "User: \(message)\nAssistant:"
        let output = model.generate(prompt: prompt, maxTokens: 200)
        return output
    }
}
```

**Installation:**
```bash
# In Package.swift dependencies hinzufÃ¼gen:
.package(url: "https://github.com/ml-explore/mlx-swift", from: "0.1.0")
```

### Option 2: CoreML

```swift
import CoreML

class CoreMLChatService: ObservableObject {
    private var model: YourCoreMLModel?

    init() {
        model = try? YourCoreMLModel(configuration: .init())
    }

    func generateResponse(for message: String) async -> String {
        guard let model = model else { return "Modell nicht geladen" }

        let input = YourCoreMLModelInput(text: message)
        let prediction = try? model.prediction(input: input)
        return prediction?.response ?? "Keine Antwort"
    }
}
```

**Modelle:**
- Download von [Hugging Face](https://huggingface.co/models?library=coreml)
- Konvertiere mit `coremltools`

### Option 3: Llama.cpp (Cross-Platform)

```swift
// Package.swift:
.package(url: "https://github.com/ShenghaiWang/SwiftLlama", from: "1.0.0")

// LocalAIService.swift:
import SwiftLlama

class LocalAIService: ObservableObject {
    private var llama: SwiftLlama?

    func loadModel(path: String) {
        llama = try? SwiftLlama(modelPath: path)
    }

    func generateResponse(for message: String) async -> String {
        let prompt = "### User: \(message)\n### Assistant:"
        let response = llama?.predict(prompt, maxTokens: 200)
        return response ?? "Fehler"
    }
}
```

## ğŸ¨ UI Anpassen

### Farben Ã¤ndern:
```swift
// In ChatView.swift, MessageBubble:

.background(message.isUser ? Color.green : Color.orange)  // Neue Farben
```

### Mehr Features hinzufÃ¼gen:
```swift
// In Message.swift:
struct Message: Identifiable {
    let id: UUID
    let text: String
    let isUser: Bool
    let timestamp: Date

    // Neue Properties:
    var isTyping: Bool = false        // Typing Indicator
    var hasError: Bool = false        // Fehler-Status
    var attachments: [URL] = []       // Datei-AnhÃ¤nge
}
```

## ğŸ” Debugging

### Xcode Console:
```swift
// In LocalAIService.swift hinzufÃ¼gen:
func generateResponse(for message: String) async -> String {
    print("ğŸ¤– Verarbeite: \(message)")

    let response = generateSimpleResponse(for: message)

    print("âœ… Antwort: \(response)")
    return response
}
```

### Xcode Breakpoints:
1. Klicken Sie auf die Zeilennummer (blauer Punkt erscheint)
2. Run mit âŒ˜R
3. App pausiert bei Breakpoint
4. Inspizieren Sie Variablen im Debug-Bereich

## ğŸ“± Plattformen

### Aktuell unterstÃ¼tzt:
- iOS 17+
- macOS 14+

### Zum Anpassen in `Package.swift`:
```swift
platforms: [
    .iOS(.v16),      // FÃ¼r iOS 16+
    .macOS(.v13),    // FÃ¼r macOS 13+
    .watchOS(.v9)    // Watch hinzufÃ¼gen
]
```

## ğŸ¤ Xcode + Cursor Workflow

### Empfohlener Workflow:

1. **Code schreiben in Cursor:**
   - AI-Assistenz nutzen
   - Schnelles Refactoring
   - Suchen und Ersetzen

2. **Testen in Xcode:**
   - Build & Run (âŒ˜R)
   - Debugger nutzen
   - UI Preview

3. **Zwischen beiden wechseln:**
   - Beide Apps kÃ¶nnen gleichzeitig offen sein
   - Xcode lÃ¤dt Ã„nderungen automatisch
   - Speichern in Cursor â†’ Reload in Xcode

### Ordner hinzufÃ¼gen (beide Tools sehen sie):

```bash
# Im Terminal:
mkdir -p SimpleChatbot/SimpleChatbot/Utilities
echo "// Utilities" > SimpleChatbot/SimpleChatbot/Utilities/Helpers.swift
```

**In Xcode:**
1. Rechtsklick auf `SimpleChatbot` Gruppe
2. "Add Files to SimpleChatbot..."
3. WÃ¤hlen Sie den `Utilities` Ordner
4. âœ… Aktivieren: "Create folder references" (blau!)
5. Klick auf "Add"

**In Cursor:**
- Ordner erscheint sofort im File Explorer
- Beide Tools sehen jetzt dieselbe Struktur! ğŸ‰

## ğŸ“š Weitere Schritte

### Lernen:
- [ ] SwiftUI Tutorials: [Apple Developer](https://developer.apple.com/tutorials/swiftui)
- [ ] ML Integration: [Create ML](https://developer.apple.com/machine-learning/create-ml/)
- [ ] MLX Swift: [GitHub](https://github.com/ml-explore/mlx-swift)

### Erweitern:
- [ ] Spracherkennung (Speech Framework)
- [ ] Text-to-Speech Ausgabe
- [ ] Nachrichten-Persistenz (SwiftData)
- [ ] Theming (Dark/Light Mode)
- [ ] Export Chat-Historie
- [ ] Mehrere Konversationen

## â“ HÃ¤ufige Fragen

### "Module 'SimpleChatbot' not found"
â†’ Warten Sie, bis Xcode Dependencies geladen hat (oben in der Mitte sehen Sie den Fortschritt)

### "Build failed"
â†’ Stellen Sie sicher, dass Sie iOS 17+ oder macOS 14+ als Target haben

### "Cursor sieht die Ordner nicht"
â†’ In Xcode: Verwenden Sie "folder references" (blaue Ordner) statt "groups" (gelbe Ordner)

### "Wie teste ich auf einem echten iPhone?"
â†’ iPhone per USB verbinden, in Xcode oben links das GerÃ¤t auswÃ¤hlen, âŒ˜R drÃ¼cken

## ğŸ‰ Viel Erfolg!

Dies ist Ihr Ãœbungsprojekt - experimentieren Sie!

**NÃ¤chste Schritte:**
1. Ã–ffnen Sie in Xcode
2. DrÃ¼cken Sie âŒ˜R
3. Chatten Sie mit dem Bot
4. Ã–ffnen Sie in Cursor und erweitern Sie ihn!

**Fragen?** Schauen Sie in `XCODE_CURSOR_INTEGRATION.md` im Hauptverzeichnis.
